{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa84324-29db-44ac-863a-abfc27413075",
   "metadata": {},
   "source": [
    "# Preprocessing the Enron dataset\n",
    "\n",
    "In this notebook we'll be preprocessing the Enron dataset. The goal is to augment the data with the information we'll need to find the emails that we want to study (and ignore the ones we don't)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136ad801-0f52-4526-9266-737b92cc0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2ea851-d26f-4292-8ca0-68841a98c7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allen-p      fischer-m\t     kitchen-l\t      phanis-s\t     smith-m\n",
      "arnold-j     forney-j\t     kuykendall-t     pimenov-v      solberg-g\n",
      "arora-h      fossum-d\t     lavorato-j       platter-p      south-s\n",
      "badeer-r     gang-l\t     lay-k\t      presto-k\t     staab-t\n",
      "bailey-s     gay-r\t     lenhart-m\t      quenet-j\t     stclair-c\n",
      "bass-e\t     geaccone-t      lewis-a\t      quigley-d      steffes-j\n",
      "baughman-d   germany-c\t     linder-e\t      rapp-b\t     stepenovitch-j\n",
      "beck-s\t     gilbertsmith-d  lokay-m\t      reitmeyer-j    stokley-c\n",
      "benson-r     giron-d\t     lokey-t\t      richey-c\t     storey-g\n",
      "blair-l      griffith-j      love-p\t      ring-a\t     sturm-f\n",
      "brawner-s    grigsby-m\t     lucci-p\t      ring-r\t     swerzbin-m\n",
      "buy-r\t     guzman-m\t     maggi-m\t      rodrique-r     symes-k\n",
      "campbell-l   haedicke-m      mann-k\t      rogers-b\t     taylor-m\n",
      "carson-m     hain-m\t     martin-t\t      ruscitti-k     tholt-j\n",
      "cash-m\t     harris-s\t     may-l\t      sager-e\t     thomas-p\n",
      "causholli-m  hayslett-r      mccarty-d\t      saibi-e\t     townsend-j\n",
      "corman-s     heard-m\t     mcconnell-m      salisbury-h    tycholiz-b\n",
      "crandell-s   hendrickson-s   mckay-b\t      sanchez-m      ward-k\n",
      "cuilla-m     hernandez-j     mckay-j\t      sanders-r      watson-k\n",
      "dasovich-j   hodge-j\t     mclaughlin-e     scholtes-d     weldon-c\n",
      "davis-d      holst-k\t     merriss-s\t      schoolcraft-d  whalley-g\n",
      "dean-c\t     horton-s\t     meyers-a\t      schwieger-j    whalley-l\n",
      "delainey-d   hyatt-k\t     mims-thurston-p  scott-s\t     white-s\n",
      "derrick-j    hyvl-d\t     motley-m\t      semperger-c    whitt-m\n",
      "dickson-s    jones-t\t     neal-s\t      shackleton-s   williams-j\n",
      "donohoe-t    kaminski-v      nemec-g\t      shankman-j     williams-w3\n",
      "donoho-l     kean-s\t     panus-s\t      shapiro-r      wolfe-j\n",
      "dorland-c    keavey-p\t     parks-j\t      shively-h      ybarbo-p\n",
      "ermis-f      keiser-k\t     pereira-s\t      skilling-j     zipper-a\n",
      "farmer-d     king-j\t     perlingiere-d    slinger-r      zufferli-j\n"
     ]
    }
   ],
   "source": [
    "! ls ../data/maildir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9860d-6177-4834-8af5-8b111eea63e1",
   "metadata": {},
   "source": [
    "We wanna convert the dataset to parquet format and then save it - then we can replace the dataset in the dvc cache with the parquet version which should be a lot easier to cache track and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c5e4c4-a9ff-46f1-8ab5-959f96ac4b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/maildir\n",
      "├── allen-p\n",
      "│   ├── all_documents\n",
      "│   │   ├── 1. -> /network/scratch/c/caleb.moses/group-project/dvc/files/md5/08/f89c6e8b9dfb55ce5d96e49e8be465\n",
      "│   │   ├── 10. -> /network/scratch/c/caleb.moses/group-project/dvc/files/md5/7e/8270c667aeecf249ad15fac5e4aacc\n",
      "│   │   ├── 100. -> /network/scratch/c/caleb.moses/group-project/dvc/files/md5/01/46e8d854f36b331d7c844029d44800\n",
      "│   │   ├── 101. -> /network/scratch/c/caleb.moses/group-project/dvc/files/md5/f9/2b88674aaea14988e17f82e7e2f87d\n",
      "│   │   ├── 102. -> /network/scratch/c/caleb.moses/group-project/dvc/files/md5/ea/92953635b60e6b874f991d508c5f4b\n",
      "│   │   ├── 103. -> /network/scratch/c/caleb.moses/group-project/dvc/files/md5/5f/72d38fe7f7d2d4d9a6b0e1b59e7c06\n",
      "│   │   ├── 104. -> /network/scratch/c/caleb.moses/group-project/dvc/files/md5/a3/165664647f9fd9eca8a8398eb0ab64\n"
     ]
    }
   ],
   "source": [
    "! tree ../data/maildir | head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e21cac-b9e0-4bb1-8c86-25c1304162fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "paths = []\n",
    "for root, dirs, files in os.walk('../data/maildir', followlinks=True):\n",
    "    for f in files:\n",
    "        paths.append(os.path.join(root, f))\n",
    "\n",
    "! head ../data/maildir/shively-h/1.\n",
    "\n",
    "enron_data = pd.DataFrame({'path': paths})\n",
    "enron_data\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import chardet\n",
    "\n",
    "def decode_email(fp):\n",
    "    with open(fp, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "\n",
    "        # Detect and use the correct encoding\n",
    "        detected_encoding = chardet.detect(raw_data)['encoding']\n",
    "        if detected_encoding is None:\n",
    "            detected_encoding = 'us-ascii'  # Default to utf-8 if encoding is undetected\n",
    "\n",
    "        try:\n",
    "            text = raw_data.decode(detected_encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            text = raw_data.decode('us-ascii', errors='replace')\n",
    "\n",
    "    return text.replace('\\r', '')\n",
    "\n",
    "def read_email(fp):\n",
    "    text = decode_email(fp)\n",
    "    \n",
    "    header, content = text.split('\\n\\n', 1)\n",
    "    \n",
    "    # Define the fields we are interested in\n",
    "    fields = ['Message-ID', 'Date', 'From', 'Subject', 'X-FileName', 'X-Origin', \n",
    "              'X-Folder', 'X-bcc', 'X-cc', 'X-To', 'X-From', 'Content-Transfer-Encoding', \n",
    "              'Content-Type', 'Mime-Version', 'To', 'Cc', 'Bcc', 'Content']\n",
    "\n",
    "    # Initialize an empty dictionary with the fields\n",
    "    email_dict = {field: '' for field in fields}\n",
    "    \n",
    "    # Set the content\n",
    "    email_dict['Content'] = content\n",
    "\n",
    "    # Temporary variable to hold the key for multi-line values\n",
    "    current_key = None\n",
    "    \n",
    "    # Split the header into lines and iterate through each line\n",
    "    lines = header.strip().split('\\n')\n",
    "    for line in lines:\n",
    "        if ':' in line:\n",
    "            key, value = line.split(':', 1)\n",
    "            key = key.strip()\n",
    "\n",
    "            # If the key is one of the fields we're interested in, or if we don't have a current key\n",
    "            if key in email_dict or current_key is None:\n",
    "                email_dict[key] = value.strip()\n",
    "                current_key = key\n",
    "            else:\n",
    "                # Append the line to the value of the previous key\n",
    "                email_dict[current_key] += ' ' + line.strip()\n",
    "        elif current_key:\n",
    "            # This is a continuation of the value from the previous line\n",
    "            email_dict[current_key] += ' ' + line.strip()\n",
    "\n",
    "    return email_dict\n",
    "\n",
    "enron_data['email'] = [read_email(fp) for fp in tqdm(enron_data.path)]\n",
    "\n",
    "%%time\n",
    "fields = pd.json_normalize(enron_data.email)\n",
    "enron_df = pd.concat([enron_data.loc[:, ['path']], fields], axis=1)\n",
    "\n",
    "enron_df.to_parquet('../data/enron_emails.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f53caa-00f0-4d69-abdc-8fd7bf1a8b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
