{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "e283403f-4c7b-4fb0-94fa-93c03684d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "f8da1fd2-8a3c-4245-8766-d146ca29f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#Create an EntityRuler for some of the names\n",
    "nameRuler = nlp.add_pipe(\"entity_ruler\")\n",
    "patterns = [\n",
    "    {\"label\": \"PERSON\", \"pattern\": [{\"lower\": 'delainey'}]},\n",
    "    {\"label\": \"PERSON\", \"pattern\": [{\"lower\": 'jmf'}]},\n",
    "    {\"label\": \"PERSON\", \"pattern\": [{\"lower\": 'dave'}]},\n",
    "    {\"label\": \"PERSON\", \"pattern\": [{\"lower\": 'forney'}]},\n",
    "    {\"label\": \"PERSON\", \"pattern\": [{\"lower\": 'lloyd'}]},\n",
    "    {\"label\": \"PERSON\", \"pattern\": [{\"lower\": 'phillip'}]},\n",
    "    {\"label\": \"PERSON\", \"pattern\": [{\"lower\": 'tj'}]},\n",
    "    {\"label\": \"ORG\", \"pattern\": [{\"lower\": 'ercot'}]},\n",
    "]\n",
    "nameRuler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "b0368f40-a387-4bd5-800b-c21a1a6e9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_replacements = {\n",
    "    'PERSON': \"Steve\",\n",
    "    'ORG': \"Apple\",\n",
    "    'GPE': \"Cupertino\",\n",
    "}\n",
    "\n",
    "def change_ents(doc, ent_replacements):\n",
    "    # find all the ents\n",
    "    regex_ent_replacements = {key: \"\" for key in ent_replacements}\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ent_replacements:\n",
    "            text = re.sub(\"\\(.*|\\).*|\\+.*\", \"\", ent.text)\n",
    "            regex_ent_replacements[ent.label_] = f\"{regex_ent_replacements[ent.label_]}|{text}\"\n",
    "    regex_ent_replacements = {key: regex_ent_replacements[key][1:] for key in regex_ent_replacements}\n",
    "\n",
    "    # replace all the ends\n",
    "    new_text = doc.text\n",
    "    for ent_label in regex_ent_replacements:\n",
    "        if regex_ent_replacements[ent_label] != \"\":\n",
    "            try:\n",
    "                new_text = re.sub(regex_ent_replacements[ent_label], ent_replacements[ent_label], new_text)\n",
    "            except:\n",
    "                continue\n",
    "    new_text = re.sub(\"[ \\n\\t]+\", \" \", new_text)\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "4ae68268-53aa-43ae-b4a6-fa07bf062e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_file = \"normal_emails.csv\"\n",
    "\n",
    "df = pd.read_csv(f\"../data/{email_file}\", index_col='Original Index')\n",
    "# token_list = [token for token in doc if \" \" not in token.text]\n",
    "\n",
    "replaced_emails = [change_ents(doc, ent_replacements) for doc in nlp.pipe(df['Email'])]\n",
    "\n",
    "df['Classify Email'] = replaced_emails\n",
    "\n",
    "df.to_csv(email_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "59efc1b1-784b-441d-8266-ad54eef5b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_file = \"exec_emails.csv\"\n",
    "\n",
    "df = pd.read_csv(f\"../data/{email_file}\", index_col='Original Index')\n",
    "# token_list = [token for token in doc if \" \" not in token.text]\n",
    "\n",
    "replaced_emails = [change_ents(doc, ent_replacements) for doc in nlp.pipe(df['Email'])]\n",
    "\n",
    "df['Classify Email'] = replaced_emails\n",
    "\n",
    "df.to_csv(email_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "0ac46771-c317-40d3-ae1f-10586a96e38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_file = \"poi_emails.csv\"\n",
    "\n",
    "df = pd.read_csv(f\"../data/{email_file}\", index_col='Original Index')\n",
    "# token_list = [token for token in doc if \" \" not in token.text]\n",
    "\n",
    "replaced_emails = [change_ents(doc, ent_replacements) for doc in nlp.pipe(df['Email'])]\n",
    "\n",
    "df['Classify Email'] = replaced_emails\n",
    "\n",
    "df.to_csv(email_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "af6b3183-8b6b-4e14-8ff4-37006030688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_emails = [change_ents(doc, ent_replacements) for doc in nlp.pipe(df['Email'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "fe3726ee-92fe-4ff5-9fee-e5e9d8dedafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Classify Email'] = replaced_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "aedbebbf-27c2-4e27-938b-476fca97340c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Sender</th>\n",
       "      <th>POI</th>\n",
       "      <th>Exec 200</th>\n",
       "      <th>Exec 300</th>\n",
       "      <th>Date</th>\n",
       "      <th>Classify Email</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Original Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18020</th>\n",
       "      <td>I have purchased from Duke   100 mw's at $51  ...</td>\n",
       "      <td>Forney</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed, 25 Apr 2001 05:37:00</td>\n",
       "      <td>I have purchased from Apple 100 mw's at $51 fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19066</th>\n",
       "      <td>We have four direct lines to the Ercot ISO tha...</td>\n",
       "      <td>Forney</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Mon, 18 Jun 2001 17:47:37</td>\n",
       "      <td>We have four direct lines to Apple that have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19817</th>\n",
       "      <td>I have purchased from Duke   100 mw's at $51  ...</td>\n",
       "      <td>Forney</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed, 25 Apr 2001 15:37:00</td>\n",
       "      <td>I have purchased from Apple 100 mw's at $51 fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21617</th>\n",
       "      <td>Guys, attached you will find a final cut on th...</td>\n",
       "      <td>Delainey</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Thu, 9 Nov 2000 10:44:00</td>\n",
       "      <td>Guys, attached you will find a final cut on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21729</th>\n",
       "      <td>Guys, attached you will find a preliminary age...</td>\n",
       "      <td>Delainey</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Mon, 30 Oct 2000 05:12:00</td>\n",
       "      <td>Guys, attached you will find a preliminary age...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499674</th>\n",
       "      <td>Greg, as per your request -  \\t*2001 bonus num...</td>\n",
       "      <td>Delainey</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Thu, 8 Nov 2001 09:20:48</td>\n",
       "      <td>Greg, as per your request - *2001 bonus number...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499934</th>\n",
       "      <td>Kevin, given the track record of mis-behaviour...</td>\n",
       "      <td>Delainey</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Mon, 22 Oct 2001 10:33:44</td>\n",
       "      <td>Steve, given the track record of mis-behaviour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500742</th>\n",
       "      <td>fyi, on a different note, given legislative ap...</td>\n",
       "      <td>Delainey</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed, 16 May 2001 01:47:00</td>\n",
       "      <td>fyi, on a different note, given legislative ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516194</th>\n",
       "      <td>HA HA HA YOU STUPID, ARROGANT FUCK ___________...</td>\n",
       "      <td>Skilling</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Fri, 30 Nov 2001 15:34:35</td>\n",
       "      <td>HA HA HA YOU STUPID, ARROGANT FUCK ___________...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516229</th>\n",
       "      <td>Fuck you, you piece of shit.  I can't wait to ...</td>\n",
       "      <td>Skilling</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed, 21 Nov 2001 12:13:05</td>\n",
       "      <td>Fuck you, you piece of shit. I can't wait to s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1109 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            Email    Sender  \\\n",
       "Original Index                                                                \n",
       "18020           I have purchased from Duke   100 mw's at $51  ...    Forney   \n",
       "19066           We have four direct lines to the Ercot ISO tha...    Forney   \n",
       "19817           I have purchased from Duke   100 mw's at $51  ...    Forney   \n",
       "21617           Guys, attached you will find a final cut on th...  Delainey   \n",
       "21729           Guys, attached you will find a preliminary age...  Delainey   \n",
       "...                                                           ...       ...   \n",
       "499674          Greg, as per your request -  \\t*2001 bonus num...  Delainey   \n",
       "499934          Kevin, given the track record of mis-behaviour...  Delainey   \n",
       "500742          fyi, on a different note, given legislative ap...  Delainey   \n",
       "516194          HA HA HA YOU STUPID, ARROGANT FUCK ___________...  Skilling   \n",
       "516229          Fuck you, you piece of shit.  I can't wait to ...  Skilling   \n",
       "\n",
       "                 POI  Exec 200  Exec 300                        Date  \\\n",
       "Original Index                                                         \n",
       "18020           True      True      True  Wed, 25 Apr 2001 05:37:00    \n",
       "19066           True      True      True  Mon, 18 Jun 2001 17:47:37    \n",
       "19817           True      True      True  Wed, 25 Apr 2001 15:37:00    \n",
       "21617           True      True      True   Thu, 9 Nov 2000 10:44:00    \n",
       "21729           True      True      True  Mon, 30 Oct 2000 05:12:00    \n",
       "...              ...       ...       ...                         ...   \n",
       "499674          True      True      True   Thu, 8 Nov 2001 09:20:48    \n",
       "499934          True      True      True  Mon, 22 Oct 2001 10:33:44    \n",
       "500742          True      True      True  Wed, 16 May 2001 01:47:00    \n",
       "516194          True      True      True  Fri, 30 Nov 2001 15:34:35    \n",
       "516229          True      True      True  Wed, 21 Nov 2001 12:13:05    \n",
       "\n",
       "                                                   Classify Email  \n",
       "Original Index                                                     \n",
       "18020           I have purchased from Apple 100 mw's at $51 fo...  \n",
       "19066           We have four direct lines to Apple that have b...  \n",
       "19817           I have purchased from Apple 100 mw's at $51 fo...  \n",
       "21617           Guys, attached you will find a final cut on th...  \n",
       "21729           Guys, attached you will find a preliminary age...  \n",
       "...                                                           ...  \n",
       "499674          Greg, as per your request - *2001 bonus number...  \n",
       "499934          Steve, given the track record of mis-behaviour...  \n",
       "500742          fyi, on a different note, given legislative ap...  \n",
       "516194          HA HA HA YOU STUPID, ARROGANT FUCK ___________...  \n",
       "516229          Fuck you, you piece of shit. I can't wait to s...  \n",
       "\n",
       "[1109 rows x 7 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a66c3929-4730-4c45-bc60-0445d431dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'Skilling'\n",
    "# for i in df[df['Sender'] == name]['Classify Email'].sample(10):\n",
    "#     print(i)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "c162d5c7-05bc-4f9a-a8d1-45b08ef534d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(email_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af03e81-b95d-45b4-8090-89ab061e7b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
